---
layout: post
title: Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation
subtitle: Lorenz Kuhn - ICLR 2023
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/cover-bengs.PNG
share-img: /assets/img/path.jpg
tags: [Semantic, Large Language Models]
comments: false
---

[**Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation**](https://openreview.net/pdf?id=VD-AYtP0dve)

by Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar
Published at the International Conference on Learning Representations (ICLR), 2023

**Abstract**

We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of ‘semantic equivalence’—different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy—an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to ‘off-the-shelf’ language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.

**Presenter**

Viktor Bengs is currently a Ph.D. student at the university of Oxford at the [Oxford Applied and Theoretical Machine Learning Group](https://oatml.cs.ox.ac.uk/) of Prof. Dr. Yarin Gal. 

**Links**

[Paper](https://openreview.net/pdf?id=VD-AYtP0dve)

