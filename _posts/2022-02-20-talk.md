---
layout: post
title: Deep Ensembles Work, But Are They Necessary?
subtitle: E. Kelly Buchanan - NeurIPS 2022
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/cover-buchanan.PNG
share-img: /assets/img/path.jpg
tags: [Ensembles]
comments: false
---

[**Deep Ensembles Work, But Are They Necessary?**](https://arxiv.org/pdf/2202.06985.pdf)

by Taiga Abe, E. Kelly Buchanan, Geoff Pleiss, Richard Zemel, John P. Cunningham
Published at the Conference on Neural Information Processing Systems (NeurIPS), 2022

**Abstract**

Ensembling neural networks is an effective way to increase accuracy, and can often match the performance of individual larger models. This observation poses a natural question: given the choice between a deep ensemble and a single neural network with similar accuracy, is one preferable over the other? Recent work suggests that deep ensembles may offer distinct benefits beyond predictive power: namely, uncertainty quantification and robustness to dataset shift. In this work, we demonstrate limitations to these purported benefits, and show that a single (but larger) neural network can replicate these qualities. First, we show that ensemble diversity, by any metric, does not meaningfully contribute to an ensemble's uncertainty quantification on out-of-distribution (OOD) data, but is instead highly correlated with the relative improvement of a single larger model. Second, we show that the OOD performance afforded by ensembles is strongly determined by their in-distribution (InD) performance, and -- in this sense -- is not indicative of any "effective robustness". While deep ensembles are a practical way to achieve improvements to predictive power, uncertainty quantification, and robustness, our results show that these improvements can be replicated by a (larger) single model.

**Presenter**

E. Kelly Buchanan is currently a Ph.D. student in the [Center for Theoretical Neuroscience](https://ctn.zuckermaninstitute.columbia.edu/) at Columbia University advised by Liam Paninski and John Cunningham.

**Links**

[Paper](https://arxiv.org/pdf/2202.06985.pdf)

[Recording](https://youtu.be/hfhKfr23WyE)
