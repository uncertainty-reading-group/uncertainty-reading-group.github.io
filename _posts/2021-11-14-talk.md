---
layout: post
title: An Impartial Take to the CNN vs Transformer Robustness Contest
subtitle: Francesco Pinto - ECCV 2022
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/cover-pinto.png
share-img: /assets/img/path.jpg
tags: [Transformers, CNN, Robustness, Calibration]
comments: false
---

[**An Impartial Take to the CNN vs Transformer Robustness Contest**](https://arxiv.org/pdf/2207.11347.pdf)

by Francesco Pinto, Philip H.S. Torr and Puneet K. Dokania
Published at the European Conference on Computer Vision (ECCV), 2022

**Abstract**

Following the surge of popularity of Transformers in Computer Vision, several studies have attempted to determine whether theycould  be  more  robust  to  distribution  shifts  and  provide  better  uncertainty estimates than Convolutional Neural Networks (CNNs). The almost unanimous conclusion is that they are, and it is often conjecturedmore  or  less  explicitly  that  the  reason  of  this  supposed  superiority  isto be attributed to the self-attention mechanism. In this paper we perform  extensive  empirical  analyses  showing  that  recent  state-of-the-art CNNs  (particularly,  ConvNeXt)  can  be  as  robust  and  reliable  oreven  sometimes  more  than  the  current  state-of-the-art  Transformers. However,  there  is  no  clear  winner.  Therefore,  although  it  is  tempting to state the definitive superiority of one family of architectures over another, they seem to enjoy similar extraordinary performances on a variety of tasks while also suffering from similar vulnerabilities such as texture, background, and simplicity biases.

**Presenter**

Francesco Pinto is currently a PhD student in the [Torr Vision group](https://torrvision.com/) in Oxford. Furthermore, he is currently a visiting research at ETH Zurich in the group of Fanny Yang. 

**Links**

[Paper](https://arxiv.org/pdf/2207.11347.pdf)
[Slides](https://docs.google.com/presentation/d/13_sRJnEbgbOc7W7PSJhQEXh2k4M7dDYma6bkNVxo1eI/edit?usp=sharing)
[Recording](https://www.youtube.com/watch?v=aOvMj4UOygQ)
